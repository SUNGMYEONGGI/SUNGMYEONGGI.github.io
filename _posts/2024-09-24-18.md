---
title: 일상 대화 요약 프로젝트 회고록
description: 해당 글에서는 일상 대화 요약 프로젝트 회고록에 대해 소개합니다.
date: 2024-09-24 23:18:57 +0900
last_modified_at: 2024-09-24 23:18:57 +0900
categories: [ 인공지능, 부트캠프 ]
tags: [ 패스트캠퍼스, 패스트캠퍼스AI부트캠프, 업스테이지패스트캠퍼스, UpstageAILab#국비지원, 패스트캠퍼스업스테이지에이아이랩, 패스트캠퍼스업스테이지부트캠프 ]
pin: false
math: false
mermaid: false
image:
  path: assets/img/upstageai_background3.png
  alt: 일상 대화 요약 프로젝트 회고록
---

# 프로젝트 개요
## 개요
Dialogue Summarization 경진대회는 주어진 데이터를 활용하여 일상 대화에 대한 요약을 효과적으로 생성하는 모델을 개발하는 대회이다. 

일상생활에서 '대화'는 항상 이루어지고 있다. 회의나 토의는 물론이고, 사소한 일상 대화 중에도 서로 다양한 주제와 입장들을 주고 받는다. 나누는 대화를 녹음해두더라도 대화 전체를 항상 다시 들을 수는 없기 때문에 요약이 필요하고, 이를 위한 통화 비서와 같은 서비스들도 등장하고 있다.

그러나 하나의 대화에서도 관점, 주제별로 정리하면 수 많은 요약을 만들 수 있다. 대화를 하는 도중에 이를 요약하게 되면 대화에 집중할 수 없으며, 대화 이후에 기억에 의존해 요약하게 되면 오해나 누락이 추가되어 주관이 많이 개입되게 된다.

이를 돕기 위해, 우리는 이번 대회에서 일상 대화를 바탕으로 요약문을 생성하는 모델을 구축하려고 한다.

![image](https://github.com/HojunJ/conventional-repo/assets/76687996/1ba682aa-f341-4e84-a788-57994fa845ba)

참가자들은 대회에서 제공된 데이터셋을 기반으로 모델을 학습하고, 대화의 요약문을 생성하는데 중점을 둡니다. 이를 위해 다양한 구조의 자연어 모델을 구축할 수 있습니다. 제공되는 데이터셋은 오직 "대화문과 요약문"입니다. 회의, 일상 대화 등 다양한 주제를 가진 대화문과, 이에 대한 요약문을 포함하고 있습니다. 참가자들은 이러한 비정형 텍스트 데이터를 고려하여 모델을 훈련하고, 요약문의 생성 성능을 높이기 위한 최적의 방법을 찾아야 합니다.

본 대회는 결과물 csv 확장자 파일을 제출하게 됩니다.

> input : 249개의 대화문  
> output : 249개의 대화 요약문

## 데이터
![image](https://velog.velcdn.com/images/d_yeon819/post/34e858c5-8866-49e2-8eda-b4bf82e00e6f/image.png)

주어진 데이터는 다음과 같았으며, 각 column의 설명은 다음과 같다.
- frame : 대화 고유 번호. 중복되는 번호가 없음.
- dialogue : 최소 2명에서 최대 7명이 등장하여 나누는 대화 내용이다. 각각의 발화자를 구분하기 위해 #Person”N”#: 을 사용하며, 발화자의 대화가 끝나면 '\n' 으로 구분한다. 이 구분자를 기준으로 하여 대화에 몇 명의 사람이 등장하는지 확인해보는 부분은 EDA 에서 다루고 있다.

# 프로젝트 팀 구성 및 역할
## 팀 구성
프로젝트 팀원으로 배정된 인원은 총 5명이며, 팀원들은 다음과 같다.

![nlp9-team](assets/img/nlp9-team.png)

## 역할 분담
- 데이터 전처리 및 EDA(Data Preprocessing and Exploratory Data Analysis)
- 기계번역, 클러스터링, 토크나이즈(Machine Translation, Clustering, Tokenization)
- 모델링 및 파라미터 튜닝(Modeling and Parameter Tuning)
- 결과 정리 및 보고서 작성(Summarization of Results and Report Writing)

모든 팀원이 위 Task를 수행했지만 각자 전문적인 역할을 수행하였다. 특히, 나는 데이터 전처리 및 EDA와 모델링에 비중을 크게 두고 프로젝트에 참여하였다.

# 프로젝트 진행 과정
우리 팀의 Rouge Score를 높여가는 자세한 Code 및 발표자료는 [Github](https://github.com/UpstageAILab3/upstage-nlp-summarization-nlp9-pub)에서 확인할 수 있다. 

# 결과
- final score
![image](https://github.com/SUNGMYEONGGI/image/blob/main/Upstage-NLP-Project_Image/final%20score.png?raw=true)

# 자체 평가 의견
## 잘했던 점
- 나의 생각대로 다양한 EDA(오타수정, 삭제)를 진행하였다.
- `trainer` 파라미터를 미세조정하면서 점수가 오르는 과정을 진행하였다.
- wandb를 통해 팀원들의 모델 학습 결과를 실시간으로 확인하며 피드백하는 방식으로 진행하였다.

## 시도 했으나 잘 되지 않았던 것들
다양한 모델을 시도해보고 싶었으나 서버 용량 이슈로 인해 중간에 서버가 여러번 끊기는 현상이 발생하였다. 대회가 끝난 직후에 LLM을 사용할 때 양자화라는 것을 하면 메모리를 좀 덜 잡아먹는 다는 것을 알게 되었다.

## 아쉬웠던 점들
멘토링을 대회가 종료된 후에 받아서 매우 아쉬웠다. 특히, 대회 발표에서 상위 등수에 있는 사람들이 LLM과 언어모델 API를 사용하는 것을 보면서 좋은 아이디어라고 생각하였는데 멘토링에서 LLM과 API를 사용해봤으면 좋았을 것 같다는 피드백에 대회 중에 멘토링을 진행했다면 우리팀도 높은 상위권에 들지 않았을까 하는 아쉬움이 있었다. 또, 팀원 대부분은 인공지능관련 혹은 비전공자이다 보니 대회를 진행하면서 강의를 겸했던 부분에서 다른 팀에 비해 프로젝트에 시간을 많이 할애하지 못한 점이 많이 아쉽다.

## 프로젝트를 통해 배운 점 또는 시사점
- 단순히 NLP 강의를 들을 때는 이론적인 부분이 많아서 단순 노이즈로만 들렸는데, 프로젝트를 진행하면서 NLP의 프로세스를 알게 되었다.
- 자연어 처리 중 '요약'이라는 태스크를 처음 겪어보면서 모델과 데이터를 어떻게 잘 만들어야 하는 지 알게 되었다. 

***
    🌜 개인 공부 기록용 블로그입니다. 오류나 틀린 부분이 있을 경우
    언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다! 😄


<a href="#" style="display: inline-block; padding: 5px 10px; color: #007bff; text-decoration: none; border: 0.5px solid #007bff; border-radius: 5px; float: right;">맨 위로 이동하기</a>